{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP+k4AJpmglyt2WEgcsa/p6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"6ydesVBMTny7","executionInfo":{"status":"ok","timestamp":1622916258671,"user_tz":-540,"elapsed":429,"user":{"displayName":"성규홍","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk9rKNJUxqcDzJrDDxURxJFCWLgip96DrtsTpfMQ=s64","userId":"14501402683079236729"}}},"source":["import torch\n","import torch.nn as nn"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yi-YhU26WQZe"},"source":["# RNN Example"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W6ACZCdjWO_m","executionInfo":{"status":"ok","timestamp":1622916677713,"user_tz":-540,"elapsed":444,"user":{"displayName":"성규홍","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk9rKNJUxqcDzJrDDxURxJFCWLgip96DrtsTpfMQ=s64","userId":"14501402683079236729"}},"outputId":"df1968c4-0904-4b36-a10c-5d856172d781"},"source":["rnn = nn.RNN(3, 3)\n","\n","# size : (5, 1, 3)\n","inputs = [torch.randn(1, 3) for _ in range(5)]\n","print(f'inputs : {inputs}')\n","\n","# first hidden state\n","hidden = torch.randn(1, 1, 3)\n","print(f'first hidden : {hidden}\\n')\n","\n","for i in inputs:\n","  # 각 iteration 마다 output이 나온다.\n","  # 각 iteration에서 나온 hidden은 다음 iteration의 hidden으로 대입된다.\n","  out, hidden = rnn(i.view(1, 1, -1), hidden)\n","  print(f'out : {out}')\n","  print(f'hidden : {hidden}\\n')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["inputs : [tensor([[-2.3100,  0.5152,  1.2212]]), tensor([[-1.0463,  1.3921, -0.3320]]), tensor([[ 0.9150, -0.0415, -0.6433]]), tensor([[-0.4164,  1.1375,  0.8015]]), tensor([[-1.7037, -0.0527,  0.4711]])]\n","first hidden : tensor([[[-1.1912,  1.1987,  1.0268]]])\n","\n","out : tensor([[[-0.9381,  0.9179,  0.4670]]], grad_fn=<StackBackward>)\n","hidden : tensor([[[-0.9381,  0.9179,  0.4670]]], grad_fn=<StackBackward>)\n","\n","out : tensor([[[-0.2259,  0.8693,  0.6049]]], grad_fn=<StackBackward>)\n","hidden : tensor([[[-0.2259,  0.8693,  0.6049]]], grad_fn=<StackBackward>)\n","\n","out : tensor([[[ 0.4133,  0.0309, -0.2637]]], grad_fn=<StackBackward>)\n","hidden : tensor([[[ 0.4133,  0.0309, -0.2637]]], grad_fn=<StackBackward>)\n","\n","out : tensor([[[0.7366, 0.0176, 0.4471]]], grad_fn=<StackBackward>)\n","hidden : tensor([[[0.7366, 0.0176, 0.4471]]], grad_fn=<StackBackward>)\n","\n","out : tensor([[[ 0.1155,  0.6665, -0.4257]]], grad_fn=<StackBackward>)\n","hidden : tensor([[[ 0.1155,  0.6665, -0.4257]]], grad_fn=<StackBackward>)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"k-GRIzjwX6tc"},"source":["# LSTM Example\n","RNN의 장기 문맥 의존성 및 gradient vanishing 현상을 해결하고자 **cell** 이라는 개념이 추가되었다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EAZfyrrZX5J2","executionInfo":{"status":"ok","timestamp":1622916847735,"user_tz":-540,"elapsed":442,"user":{"displayName":"성규홍","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk9rKNJUxqcDzJrDDxURxJFCWLgip96DrtsTpfMQ=s64","userId":"14501402683079236729"}},"outputId":"57bbaa34-78c1-4608-971d-8e57981fa468"},"source":["lstm = nn.LSTM(3, 3)\n","\n","# size : (5, 1, 3)\n","inputs = [torch.randn(1, 3) for _ in range(5)]\n","print(f'inputs : {inputs}')\n","\n","# first hidden state\n","hidden = (torch.randn(1, 1, 3), # hidden state\n","          torch.randn(1, 1, 3)) # cell state\n","print(f'first hidden : {hidden}\\n')\n","\n","for i in inputs:\n","  # 각 iteration 마다 output이 나온다.\n","  # 각 iteration에서 나온 hidden은 다음 iteration의 hidden으로 대입된다.\n","  out, hidden = lstm(i.view(1, 1, -1), hidden)\n","  print(f'out : {out}')\n","  print(f'hidden : {hidden[0]}')\n","  print(f'cell : {hidden[1]}\\n')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["inputs : [tensor([[-0.3577, -0.1670, -0.2724]]), tensor([[-0.5947,  0.9907, -0.2995]]), tensor([[ 1.1773,  0.4212, -1.9770]]), tensor([[0.2326, 1.9729, 0.4413]]), tensor([[-0.2317,  0.7693,  0.2085]])]\n","first hidden : (tensor([[[ 0.1911,  0.1175, -0.4515]]]), tensor([[[ 0.5990, -0.0009,  0.3376]]]))\n","\n","out : tensor([[[ 0.2051, -0.0994,  0.0920]]], grad_fn=<StackBackward>)\n","hidden : tensor([[[ 0.2051, -0.0994,  0.0920]]], grad_fn=<StackBackward>)\n","cell : tensor([[[ 0.3756, -0.1355,  0.2962]]], grad_fn=<StackBackward>)\n","\n","out : tensor([[[0.1838, 0.0831, 0.2084]]], grad_fn=<StackBackward>)\n","hidden : tensor([[[0.1838, 0.0831, 0.2084]]], grad_fn=<StackBackward>)\n","cell : tensor([[[0.3772, 0.1073, 0.5253]]], grad_fn=<StackBackward>)\n","\n","out : tensor([[[0.0494, 0.0586, 0.0313]]], grad_fn=<StackBackward>)\n","hidden : tensor([[[0.0494, 0.0586, 0.0313]]], grad_fn=<StackBackward>)\n","cell : tensor([[[0.2685, 0.1262, 0.1432]]], grad_fn=<StackBackward>)\n","\n","out : tensor([[[0.1456, 0.3602, 0.1551]]], grad_fn=<StackBackward>)\n","hidden : tensor([[[0.1456, 0.3602, 0.1551]]], grad_fn=<StackBackward>)\n","cell : tensor([[[0.4290, 0.4937, 0.5267]]], grad_fn=<StackBackward>)\n","\n","out : tensor([[[0.2320, 0.4726, 0.1873]]], grad_fn=<StackBackward>)\n","hidden : tensor([[[0.2320, 0.4726, 0.1873]]], grad_fn=<StackBackward>)\n","cell : tensor([[[0.4390, 0.7001, 0.6013]]], grad_fn=<StackBackward>)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bSfnDPdrYwyZ"},"source":["# RNN Neural Network Implementation"]},{"cell_type":"code","metadata":{"id":"sttHF-lJTv3u","executionInfo":{"status":"ok","timestamp":1622915888757,"user_tz":-540,"elapsed":4,"user":{"displayName":"성규홍","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk9rKNJUxqcDzJrDDxURxJFCWLgip96DrtsTpfMQ=s64","userId":"14501402683079236729"}}},"source":["class RNN(nn.Module):\n","  def __init__(self, input_size, hidden_size, output_size):\n","    self.hidden_size = hidden_size\n","\n","    self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n","    self.i2o = nn.Linear(input_size + hidden_size, output)\n","    self.softmax = nn.LogSoftmax(dim=1)\n","\n","  def forward(self, input, hidden):\n","    combined = torch.cat((input, hidden), dim=1)\n","    hidden = self.i2h(combined)\n","    output = self.i2o(combined)\n","    output = self.softmax(output)\n","    return output, hidden\n","\n","  def initHidden(self):\n","    return torch.zeros(1, self.hidden_size)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wv1V2YzEY2yl"},"source":["# RNN Training"]},{"cell_type":"code","metadata":{"id":"FiNdqG64TydE","executionInfo":{"status":"ok","timestamp":1622915910533,"user_tz":-540,"elapsed":439,"user":{"displayName":"성규홍","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk9rKNJUxqcDzJrDDxURxJFCWLgip96DrtsTpfMQ=s64","userId":"14501402683079236729"}}},"source":["criterion = nn.NLLLoss().cuda()\n","learning_rate = 0.005\n","\n","rnn = RNN(i, h, o).cuda()\n","\n","def train(category_tensor, line_tensor):\n","  hidden = rnn.initHidden().cuda()\n","\n","  rnn.zero_grad()\n","\n","  # 하나의 라인에 대한 첫번째 차원 (글자수)\n","  for i in range(line_tenseor.size()[0]):\n","    output, hidden = rnn(line_tensor[i].cuda(), hidden)\n","\n","  loss = criterion(output, category_tensor)\n","  loss.backward()\n","\n","  for p in rnn.parameters():\n","    p.data.dd_(p.grad.data, alpha=-learning_rate)\n","\n","  return output, loss.item()"],"execution_count":4,"outputs":[]}]}